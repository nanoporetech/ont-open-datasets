<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Oxford Nanopore Technologies Open Datasets]]></title><description><![CDATA[Discover Open Datasets provided by Oxford Nanopore Technologies.]]></description><link>https://nanoporetech.github.io/ont-open-datasets</link><generator>GatsbyJS</generator><lastBuildDate>Wed, 23 Sep 2020 16:13:57 GMT</lastBuildDate><item><title><![CDATA[Katuali analysis pipeline for preparing human datasets]]></title><description><![CDATA[Our recent GM24385 data release contains data from multiple
flowcells and analytes for both the R9.4.1 and R10.3 flowcell chemistries. The…]]></description><link>https://nanoporetech.github.io/ont-open-datasets/katuali_human_pipeline/</link><guid isPermaLink="false">https://nanoporetech.github.io/ont-open-datasets/katuali_human_pipeline/</guid><pubDate>Tue, 22 Sep 2020 00:04:00 GMT</pubDate><content:encoded>&lt;p&gt;Our recent &lt;a href=&quot;/ont-open-datasets/gm24385_2020.09&quot;&gt;GM24385 data release&lt;/a&gt; contains data from multiple
flowcells and analytes for both the R9.4.1 and R10.3 flowcell chemistries. The
uploaded data contains the primary sequencer output data; the full MinKNOW
output directory for the runs is included verbatim. The release seperately
contains a directory structure resulting from the application of a snakemake
analysis pipeline. Here we provide details of how this workflow was executed
and its outputs.&lt;/p&gt;
&lt;h3&gt;Background&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/nanoporetech/katuali&quot;&gt;Katuali&lt;/a&gt; is a set of
&lt;a href=&quot;https://snakemake.readthedocs.io/&quot;&gt;Snakemake&lt;/a&gt; analysis pipelines for basic
analysis of nanopore sequencing data. It can perform basic tasks such as
basecalling, alignment of reads, assembly, and evaluation and benchmarking of
such algorithms. This can be performed at scale on large compute clusters on
local or cloud infrastructure.&lt;/p&gt;
&lt;p&gt;For the GM24385 release Katuali was used to construct secondary analyses in a
documented and reproducible fashion. As katuali is open source, it is possible
for users to reconstruct these secondary analyses for themselves from the
primary data. We have uploaded the results of these analysis to provide
benchmarking data and make available useful resources for others to perform
further analysis.&lt;/p&gt;
&lt;p&gt;The Katuali pipeline used for the &lt;a href=&quot;/ont-open-datasets/gm24385_2020.09&quot;&gt;GM24385 data release&lt;/a&gt;
provides four main outputs:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Align basecalls to reference sequence retaining all primary, secondary and
supplementary alignments are kept&lt;/li&gt;
&lt;li&gt;Filter .bam file to list of regions defined in configuration file retaining
only primary alignments.&lt;/li&gt;
&lt;li&gt;Produce read statistics from per-region .bams.&lt;/li&gt;
&lt;li&gt;Repack/group source .fast5 files according to primary alignment .bams to
produce per-region .fast5 file sets.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These outputs provide added value to the primary data, and users can extend and
adapt the katuali pipeline and configuration to calculate additional outputs.&lt;/p&gt;
&lt;h3&gt;Katuali configuration for GM24385 release&lt;/h3&gt;
&lt;p&gt;Katuali builds on native Snakemake functionality to provide a way of mapping
and analysis pipeline across multiple inputs with minimal fuss. How this is
achieved is describe in the katuali &lt;a href=&quot;https://nanoporetech.github.io/katuali/examples.html#automatic-generation-of-custom-pipeline-targets&quot;&gt;documentation&lt;/a&gt;. This functionality can be used to simulataneously
process data from multiple flowcells.&lt;/p&gt;
&lt;p&gt;A single configuration file is used to control Katuali’s behaviour: what input
data it will use, what pipelines it will run, and the configuration of external
programs that it runs. The configuration file can be created from the
provided template using the &lt;a href=&quot;https://nanoporetech.github.io/katuali/tests.html#predefined-workflows&quot;&gt;katuali_config&lt;/a&gt;
command.&lt;/p&gt;
&lt;p&gt;For the purposes of the GM24385 data release this file was then customised with
details of the input datasets (the &lt;code class=&quot;language-text&quot;&gt;.fast5&lt;/code&gt;/&lt;code class=&quot;language-text&quot;&gt;.fastq&lt;/code&gt; files from MinKNOW) and a
description of the outputs that were required. The resulting files are included
in the data release under the &lt;code class=&quot;language-text&quot;&gt;config&lt;/code&gt; folder at:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;s3://ont-open-data/gm24385_2020.09/config/&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See our &lt;a href=&quot;/ont-open-datasets/tutorials/&quot;&gt;tutorials&lt;/a&gt; page for details on how to download these
files.&lt;/p&gt;
&lt;h4&gt;Setup of input directories&lt;/h4&gt;
&lt;p&gt;Katuali can be used to perform basecalling from &lt;code class=&quot;language-text&quot;&gt;.fast5&lt;/code&gt; files to produce
standard &lt;code class=&quot;language-text&quot;&gt;.fastq&lt;/code&gt; sequence files. However since basecalling was performed
during the sequencing experiments we can sidestep the basecalling procedure
and simply bootstrap the Katuali output directory with the already computed
basecalls. To do this the &lt;code class=&quot;language-text&quot;&gt;setup_katuali.sh&lt;/code&gt; program, located at:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;s3://ont-open-data/gm24385_2020.09/config/setup_katuali.sh&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;was used. This prepares a directory structure that Katuali would otherwise
produce itself whilst avoiding some expensive computations. Seperate top-level
Katuali directories were created to group flowcell data from R9.4.1 and R10.3
flowcells.&lt;/p&gt;
&lt;h4&gt;Important aspects of configuration file&lt;/h4&gt;
&lt;p&gt;The template configuration files need only minor customisation for the GM24385
dataset. Firstly the &lt;code class=&quot;language-text&quot;&gt;DATA:&lt;/code&gt; section requires specifying, for example the
R9.4.1 file contains an entries such as the following (one per flowcell):&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;DATA:
    &amp;#39;20200914_1356_6F_PAF26223_da14221a&amp;#39;:
        &amp;#39;REFERENCE&amp;#39;: &amp;#39;ref/GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta&amp;#39;
        &amp;#39;SPLIT_FAST5_REGIONS&amp;#39;:
            [&amp;#39;chr1&amp;#39;, &amp;#39;chr2&amp;#39;, &amp;#39;chr3&amp;#39;, &amp;#39;chr4&amp;#39;, &amp;#39;chr5&amp;#39;, &amp;#39;chr6&amp;#39;, &amp;#39;chr7&amp;#39;, &amp;#39;chr8&amp;#39;, &amp;#39;chr9&amp;#39;, &amp;#39;chr10&amp;#39;,
            &amp;#39;chr11&amp;#39;, &amp;#39;chr12&amp;#39;, &amp;#39;chr13&amp;#39;, &amp;#39;chr14&amp;#39;, &amp;#39;chr15&amp;#39;, &amp;#39;chr16&amp;#39;, &amp;#39;chr17&amp;#39;, &amp;#39;chr18&amp;#39;, &amp;#39;chr19&amp;#39;, &amp;#39;chr20&amp;#39;,
            &amp;#39;chr21&amp;#39;, &amp;#39;chr22&amp;#39;, &amp;#39;chrX&amp;#39;, &amp;#39;chrY&amp;#39;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The first item here is simply the name MinKNOW output directory. The
&lt;code class=&quot;language-text&quot;&gt;REFERENCE&lt;/code&gt; entry is a relative filepath to the genomic reference sequence
appropriate to the sample; in the case of the GM24385 dataset this is simply
the human reference genome. The final entry in the above is a list of sequence
identifies (corresponding to entries in the &lt;code class=&quot;language-text&quot;&gt;REFERENCE&lt;/code&gt; file) indicating how
the dataset should be separated after alignment of sequences to the reference.&lt;/p&gt;
&lt;p&gt;The second important customisation of the template configuration file is the specification
of which output files should be created. This appears in the &lt;code class=&quot;language-text&quot;&gt;PIPELINES&lt;/code&gt; section:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;PIPELINES:
    all_initial: [
        # do alignments, split bams and fast5s by regions
        &amp;quot;{DATA}/guppy_v4.0.11_r10.3_hac_prom/align_unfiltered/{SPLIT_FAST5_REGIONS}/fast5/&amp;quot;,
    ]
    all_add_alignment_stats: [
        # calculate alignment stats
        &amp;quot;{DATA}/guppy_v4.0.11_r10.3_hac_prom/align_unfiltered/calls2ref_stats.txt&amp;quot;,
        &amp;quot;{DATA}/guppy_v4.0.11_r10.3_hac_prom/align_unfiltered/{SPLIT_FAST5_REGIONS}/calls2ref_stats.txt&amp;quot;
    ]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What these so-called “targets” cause Katuali and Snakemake to calculate is discussed below.
To have katuali perform the calculation for all items in the &lt;code class=&quot;language-text&quot;&gt;DATA&lt;/code&gt; section it is sufficient
to run katuali with, for example:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;katuali all_initial --configfile ../../config/r9.4.1.config&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;from the directory corresponding to:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;s3://ont-open-data/gm24385_2020.09/analysis/r9.4.1/&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Katuali replaces the &lt;code class=&quot;language-text&quot;&gt;{DATA}&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;{SPLIT_FAST5_REGIONS}&lt;/code&gt; tags in the listings above with
all possible values listed in the &lt;code class=&quot;language-text&quot;&gt;DATA&lt;/code&gt; section of the configuration file. The resulting
matrix of targets is given to Snakemake to perform the workflows.&lt;/p&gt;
&lt;h3&gt;Pipeline data flow and output descriptions&lt;/h3&gt;
&lt;p&gt;The filepath targets defined in the Katuali configuration files trigger
Snakemake to perform all necessary calculations required to produce the
requested files. Users interested in the Snakemake rules used to produce all
files should consult the Katuali documentation and source files
&lt;a href=&quot;https://github.com/nanoporetech/katuali/tree/master/katuali/data&quot;&gt;here&lt;/a&gt;, which
are grouped logically according to function.&lt;/p&gt;
&lt;p&gt;Katuali has for the most part a convention that outputs which are derived
directly from an input (or previous intermediate output) are stored in a
sub-directory of that previous input. This leads to a continued deepening of
the directory structure. A benefit of this approach is the ability to
recursively calculate new outputs of the same type without having to write
multiple rules. Downside of the approach are that it is not always easy to see
which items are the immediate outputs of an analysis stage and which are the
outputs of subsequent stages. To aid users who do not wish to examine the
Snakemake files included in Katuali, the directory listing below will aid
comprehension.&lt;/p&gt;
&lt;p&gt;Katuali generically labels results of analysis stages using a
&lt;code class=&quot;language-text&quot;&gt;&amp;lt;stage&amp;gt;_&amp;lt;suffix&amp;gt;&lt;/code&gt; form, for example in the below the top level
&lt;code class=&quot;language-text&quot;&gt;&amp;lt;guppy_v4.0.11_r10.3_hac_prom&amp;gt;&lt;/code&gt; indicates results under this level
are results of the Guppy basecaller using the settings specified
in the Katuali configuration file under the tag &lt;code class=&quot;language-text&quot;&gt;v4.0.11_r10.3_hac_prom&lt;/code&gt;.
Similarly &lt;code class=&quot;language-text&quot;&gt;&amp;lt;align_unfiltered&amp;gt;&lt;/code&gt; indicates results from the alignment
rule generated using the &lt;code class=&quot;language-text&quot;&gt;unfiltered&lt;/code&gt; settings.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;.
├── guppy_v4.0.11_r10.3_hac_prom
│   ├── basecalls.fastq
│   ├── sequencing_summary.txt
│   ├── align_unfiltered
│   │   ├── calls2ref.bam
│   │   ├── calls2ref.bam.bai
│   │   ├── calls2ref_stats.txt
│   │   ├── chr1
│   │   │   ├── calls2ref.bam
│   │   │   ├── calls2ref.bam.bai
│   │   │   ├── calls2ref_stats.txt
│   │   │   ├── fast5
│   │   │   │   ├── batch0.fast5
│   │   │   │   ├── batch1.fast5
│   │   │   │   ├── ...
│   │   │   │   └── filename_mapping.txt
│   │   │   └── readlist.txt
│   │   ├── chr2
┊	┊   ┊	...
└── reads -&amp;gt; &amp;lt;link to MinKNOW fast5_pass directory&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;(Log files have been omitted from the above listing).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The guppy analysis stage&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Guppy analysis stage has two outputs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;basecalls.fastq&lt;/code&gt; - all basecalls from the basecaller in a single file.&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;sequencing_summary.txt&lt;/code&gt; - per-read summary information (as produced by MinKNOW).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Alignment analysis stage&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The alignment stage of the workflow produced the following files under the
&lt;code class=&quot;language-text&quot;&gt;align_unfiltered&lt;/code&gt; directory. The &lt;code class=&quot;language-text&quot;&gt;unfiltered&lt;/code&gt; suffix relates to the fact that
all alignments are retained, not simply the primary alignment of each read.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;calls2ref.bam&lt;/code&gt; - the alignments of reads to the supplied reference.&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;calls2ref.bam.bai&lt;/code&gt; - an index file for the alignments.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An auxiliary target of the Katuali pipeline produces the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;calls2ref_stats.txt&lt;/code&gt; - per-read statistics calculated from the corresponding
&lt;code class=&quot;language-text&quot;&gt;calls2ref.bam&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Alignment filtering stage&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Having aligned the basecall data, Katuali separates the basecalls and read data
stored in the source &lt;code class=&quot;language-text&quot;&gt;.fast5&lt;/code&gt; data by the regions specified in the Katuali
config. A directory is produced by region, for example &lt;code class=&quot;language-text&quot;&gt;chr1&lt;/code&gt; in the listing
above. Under this we find:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;calls2ref*&lt;/code&gt; - files analagous to those in the &lt;code class=&quot;language-text&quot;&gt;align_unfiltered&lt;/code&gt; directory
but containing only those reads with primary alignments to the given region.&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;readlist.txt&lt;/code&gt; - a simple text table containing the read identifiers of the
requisite reads.&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;fast5&lt;/code&gt; - a directory containing &lt;code class=&quot;language-text&quot;&gt;.fast5&lt;/code&gt; files constructed from the original
MinKNOW &lt;code class=&quot;language-text&quot;&gt;.fast5&lt;/code&gt; files but containing only the requisite reads. The file
&lt;code class=&quot;language-text&quot;&gt;filename_mapping.txt&lt;/code&gt; provides a read identifier to filename mapping.&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[GM24385 Dataset Release]]></title><description><![CDATA[We are happy to annouce the release of a Nanopore sequencing dataset
of the Genome in a Bottle sample GM24385. Multiple PromethION flowcells…]]></description><link>https://nanoporetech.github.io/ont-open-datasets/gm24385_2020.09/</link><guid isPermaLink="false">https://nanoporetech.github.io/ont-open-datasets/gm24385_2020.09/</guid><pubDate>Tue, 22 Sep 2020 00:03:00 GMT</pubDate><content:encoded>&lt;p&gt;We are happy to annouce the release of a Nanopore sequencing dataset
of the Genome in a Bottle sample GM24385.&lt;/p&gt;
&lt;p&gt;Multiple PromethION flowcells using both the R9.4.1 and R10.3 nanopores.
The direct sequencer output is included, raw signal data stored in
.fast5 files and basecalled data in .fastq file. Additional secondary
analyses are included, notably alignments of sequence data to the
reference genome are provided along with statistics derived from these.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The following cell lines/DNA samples were obtained from the NIGMS Human
Genetic Cell Repository at the Coriell Institute for Medical Research:
GM24385.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Whats included?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The dataset comprises multiple R9.4.1 and R10.3 flowcells of multiple
separately prepared samples; each sample was run on each flowcell type.&lt;/p&gt;
&lt;p&gt;The initial sequencer outputs are included in self container directories.
In addition derived outputs from an automated pipeline are stored
separately.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Details concerning sample preparations&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;High molecular weight DNA from GM24385 lymphoblastoid cells was prepared by
Evotec.&lt;/li&gt;
&lt;li&gt;Circulomics Short Read Eliminator XL protocol was used to deplete DNA
fragments &amp;#x3C; 40kb in length.&lt;/li&gt;
&lt;li&gt;(optional) Megaruptor was used to shear DNA to obtain DNA fragments with
an approximate N50 of 30kb.&lt;/li&gt;
&lt;li&gt;DNA was end repaired and dA tailed prior to LSK based library preparation.&lt;/li&gt;
&lt;li&gt;DNA sequencing was performed using PromethION device.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following cell line samples were obtained from the NIGMS Human Genetic Cell
Repository at the Coriell Institute for Medical Research: GM24385&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Location of the data&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The data is located in an Amazon Webservice S3 bucket at:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;s3://ont-open-data/gm24385_2020.09/&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See the &lt;a href=&quot;/ont-open-datasets/tutorials/&quot;&gt;tutorials&lt;/a&gt; page for information on downloading the dataset.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Description of available data&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The uploaded dataset has been prepared using a snakemake pipeline to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Align basecalls to reference sequence. All primary, secondary and
supplementary alignments are kept&lt;/li&gt;
&lt;li&gt;Filter .bam file to list of regions defined in configuration file
retaining only primary alignments.&lt;/li&gt;
&lt;li&gt;Produce read statistics from per-region .bams.&lt;/li&gt;
&lt;li&gt;Repack/group source .fast5 files according to primary alignment .bams
to produce per-region .fast5 file sets.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For more details see our &lt;a href=&quot;/ont-open-datasets/katuali_human_pipeline/&quot;&gt;post&lt;/a&gt; detailing the
pipeline and its outputs.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[ONT Open Datasets Tutorials]]></title><description><![CDATA[Below you will find helpful information and links out to tutorials for
datasets within the Open Datasets project. How can I access the data…]]></description><link>https://nanoporetech.github.io/ont-open-datasets/tutorials/</link><guid isPermaLink="false">https://nanoporetech.github.io/ont-open-datasets/tutorials/</guid><pubDate>Tue, 22 Sep 2020 00:01:00 GMT</pubDate><content:encoded>&lt;p&gt;Below you will find helpful information and links out to tutorials for
datasets within the Open Datasets project.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;How can I access the data?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;All the data is stored under in an Amazon Web Services S3 bucket:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;s3://ont-open-data&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This public has public permissions for anyone to obtain the data
without requiring login credentials. To download the data we
recommend using the &lt;a href=&quot;https://aws.amazon.com/cli/&quot;&gt;AWS command line interface&lt;/a&gt;.
With the CLI installed listing the datasets can be performed with:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;aws s3 ls s3://ont-open-data/&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There will be a subdirectory per dataset release. Inside each dataset
will be contained a README.md file with brief details. This website
will contain additional details for each dataset.&lt;/p&gt;
&lt;p&gt;To download datasets or extracts thereof we recommend using the &lt;code class=&quot;language-text&quot;&gt;sync&lt;/code&gt;
command:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;aws s3 sync s3://ont-open-data/gm24385_2020.09 gm24385_2020.09&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Datasets may be added to or amended over time so using &lt;code class=&quot;language-text&quot;&gt;sync&lt;/code&gt; can be
used with a previously fetch copy to update with the latest changes
and additions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Running workflows using ONT’s EPI2ME platform&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Oxford Nanopore’s &lt;a href=&quot;https://epi2me.nanoporetech.com/&quot;&gt;EPI2ME&lt;/a&gt;
platform includes several workflows for analysing
genomics datasets in the cloud with Amazon Web Services, reducing the
computational burden on the users local compute infrastructure.
For example, the &lt;a href=&quot;https://community.nanoporetech.com/protocols/epi2me/v/mte_1014_v1_revba_11apr2016/human-alignment-grch38&quot;&gt;FASTQ Human Alignment GRCh38&lt;/a&gt;
can be used to perform alignment of nanopore sequencing reads to
the human reference genome to obtain industry standard BAM file outputs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;How can I recreate the analysis directories?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;With each dataset release we will include details of how the analysis
directories were constructed from the primary inputs. For example for
the &lt;a href=&quot;/ont-open-datasets/gm24385_2020.09&quot;&gt;GM24385&lt;/a&gt; dataset release &lt;a href=&quot;/ont-open-datasets/katuali_human_pipeline&quot;&gt;this page&lt;/a&gt;
contains details of the Snakemake pipeline used.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[ONT Open Datasets Launch]]></title><description><![CDATA[The ont-open-data registry provides reference sequencing data from Oxford
Nanopore Technologies to support, Exploration of the…]]></description><link>https://nanoporetech.github.io/ont-open-datasets/launch_annouce/</link><guid isPermaLink="false">https://nanoporetech.github.io/ont-open-datasets/launch_annouce/</guid><pubDate>Tue, 22 Sep 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;The ont-open-data registry provides reference sequencing data from Oxford
Nanopore Technologies to support,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Exploration of the characteristics of nanopore sequence data,&lt;/li&gt;
&lt;li&gt;Assessment and reproduction of performance benchmarks,&lt;/li&gt;
&lt;li&gt;Example datasets for analysis on EPI2ME, Oxford Nanopore Technologies’ cloud
compute infrastructure,&lt;/li&gt;
&lt;li&gt;Development of tools and methods.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The data deposited showcases DNA sequences from a representative subset of
sequencing chemistries. The datasets correspond to publicly-available reference
samples (e.g. GM24385 as reference human). Raw data are provided with metadata
and scripts to describe sample and data provenance.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[About]]></title><description><![CDATA[The ont-open-data registry provides reference sequencing data from Oxford
Nanopore Technologies to support, Exploration of the…]]></description><link>https://nanoporetech.github.io/ont-open-datasets/</link><guid isPermaLink="false">https://nanoporetech.github.io/ont-open-datasets/</guid><pubDate>Tue, 22 Sep 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;The ont-open-data registry provides reference sequencing data from Oxford
Nanopore Technologies to support,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Exploration of the characteristics of nanopore sequence data,&lt;/li&gt;
&lt;li&gt;Assessment and reproduction of performance benchmarks,&lt;/li&gt;
&lt;li&gt;Example datasets for analysis on EPI2ME, Oxford Nanopore Technologies’ cloud
compute infrastructure,&lt;/li&gt;
&lt;li&gt;Development of tools and methods.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The data deposited showcases DNA sequences from a representative subset of
sequencing chemistries. The datasets correspond to publicly-available reference
samples (e.g. GM24385 as reference human). Raw data are provided with metadata
and scripts to describe sample and data provenance.&lt;/p&gt;</content:encoded></item></channel></rss>